{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-nearest neighbor model with twidf\n",
    "\n",
    "Here the k-nn is not at all limited by the sender, nearest neighbours are queried in the entire training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import itertools\n",
    "from matplotlib import pyplot as plt\n",
    "import math\n",
    "import numpy as np\n",
    "import operator\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import random\n",
    "import re\n",
    "import scipy\n",
    "import string\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "\n",
    "import src.knntools as knntools\n",
    "import src.postprocess as postprocess\n",
    "import src.preprocess as preprocess\n",
    "import src.tfidftools as tfidftools\n",
    "import src.tools as tools\n",
    "import src.recencytools as recency\n",
    "import src.scoring as scoring\n",
    "import src.textembeddingtools as texttools\n",
    "import src.graphwordstools as graphtools\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path_to_data = 'data/'\n",
    "\n",
    "training = pd.read_csv(path_to_data + 'training_set.csv', sep=',', header=0)\n",
    "\n",
    "training_info = pd.read_csv(\n",
    "    path_to_data + 'training_info.csv', sep=',', parse_dates=True, header=0)\n",
    "\n",
    "test = pd.read_csv(path_to_data + 'test_set.csv', sep=',', header=0)\n",
    "\n",
    "test_info = pd.read_csv(path_to_data + 'test_info.csv',\n",
    "                        sep=',', parse_dates=True, header=0)\n",
    "path_to_results = 'results/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing training !\n",
      "\n",
      "Processing val !\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_info, train_email_ids_per_sender, val_info, val_email_ids_per_sender = scoring.get_train_val(training, training_info, train_frac=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_body_dict = preprocess.body_dict_from_panda(train_info)\n",
    "val_body_dict = preprocess.body_dict_from_panda(val_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_token_dict = texttools.get_token_dict(train_body_dict)\n",
    "val_token_dict = texttools.get_token_dict(val_body_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute average length of doc in tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_doc_lengths_dic, train_average_doc_len = texttools.get_doc_length_info(train_token_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_idf_dic, train_idf_words = tfidftools.get_idf_dic(train_token_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7161\n"
     ]
    }
   ],
   "source": [
    "print(len(train_idf_dic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute training twidf vectors and other needed variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "CPU times: user 13min 52s, sys: 27.8 s, total: 14min 20s\n",
      "Wall time: 15min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "twidf_matrix, twidf_mids = graphtools.get_twidf_matrix(train_token_dict, train_doc_lengths_dic,\n",
    "                                                       train_average_doc_len, train_idf_dic,\n",
    "                                                       train_idf_words, 0.003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_doc_lengths_dic, average_test_length = texttools.get_doc_length_info(val_token_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute validation twidf vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "val_vectors = graphtools.get_twidf_vectors_from_tokens(train_idf_dic, train_idf_words,\n",
    "                                                       val_token_dict, train_average_doc_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute recipient scores for each mid\n",
    "\n",
    "Scores for candidate are computed by summing the cosine distances for the nearest documents to the email in which the candidate is indeed a recipient "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "mid_recipient_scores = knntools.compute_twidf_similarity_scores(twidf_matrix, twidf_mids,\n",
    "                                                                val_vectors, train_info,\n",
    "                                                                nb_similars=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "twidf_predictions = knntools.similar_dic_to_standard(mid_recipient_scores, nb_recipients=50)\n",
    "current_score = scoring.compute_prediction_mad(twidf_predictions, val_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.208050623216\n"
     ]
    }
   ],
   "source": [
    "print(current_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_to_ranks = 'ranks_val/twidf-knn-k-{nb_neighbors}-rec'.format(nb_neighbors=50)\n",
    "with open(path_to_ranks, 'wb') as infile:\n",
    "              pickle.dump(twidf_predictions, infile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  },
  "widgets": {
   "state": {
    "0f07d121bb0f424cb54aab172cfb298c": {
     "views": [
      {
       "cell_index": 3
      }
     ]
    },
    "248866cd4abf4b8288f472ea0acf74aa": {
     "views": [
      {
       "cell_index": 16
      }
     ]
    },
    "2b7c7114c66a47848dfb41efd6e405d4": {
     "views": [
      {
       "cell_index": 3
      }
     ]
    },
    "62174209b0474f7e9bcd867784a1af50": {
     "views": [
      {
       "cell_index": 11
      }
     ]
    },
    "62b4a44cfe38467b990b634d32b21f0a": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "6443f97fdc21405d8124b24bced84d1f": {
     "views": [
      {
       "cell_index": 11
      }
     ]
    },
    "646a47e4ad1e497283a19d2f3b34f8bd": {
     "views": [
      {
       "cell_index": 11
      }
     ]
    },
    "78a770a4897541e6aceb85e9b7293a08": {
     "views": [
      {
       "cell_index": 4
      }
     ]
    },
    "9e9c2a51cda74199a7466f83775c05ff": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "a074b80595064af59365caa64e9f101a": {
     "views": [
      {
       "cell_index": 2
      }
     ]
    },
    "aea6e5a682dc4f00aaa1d0386903d27f": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    },
    "c164d86540c140dea893dc3491a24744": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    },
    "dc18fb58c965410f82d5945dfbc7f6cb": {
     "views": [
      {
       "cell_index": 3
      }
     ]
    },
    "dd5e818d126a436c92bae825c2461177": {
     "views": [
      {
       "cell_index": 14
      }
     ]
    },
    "f71aee483acc4d2a86f944834231ffe5": {
     "views": [
      {
       "cell_index": 4
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
