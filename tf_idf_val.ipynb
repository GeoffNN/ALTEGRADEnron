{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import operator\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import random\n",
    "import scipy\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "\n",
    "import src.knntools as knntools\n",
    "import src.postprocess as postprocess\n",
    "import src.preprocess as preprocess\n",
    "import src.tfidftools as tfidftools\n",
    "import src.tools as tools\n",
    "import src.recencytools as recency\n",
    "import src.scoring as scoring\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path_to_data = 'data/'\n",
    "\n",
    "training = pd.read_csv(path_to_data + 'training_set.csv', sep=',', header=0)\n",
    "\n",
    "training_info = pd.read_csv(\n",
    "    path_to_data + 'training_info.csv', sep=',', parse_dates=True, header=0)\n",
    "\n",
    "test = pd.read_csv(path_to_data + 'test_set.csv', sep=',', header=0)\n",
    "\n",
    "test_info = pd.read_csv(path_to_data + 'test_info.csv',\n",
    "                        sep=',', parse_dates=True, header=0)\n",
    "path_to_results = 'results/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing training !\n",
      "processed 0 senders\n",
      "processed 20 senders\n",
      "processed 40 senders\n",
      "processed 60 senders\n",
      "processed 80 senders\n",
      "processed 100 senders\n",
      "processed 120 senders\n",
      "Processing val !\n",
      "processed 0 senders\n",
      "processed 20 senders\n",
      "processed 40 senders\n",
      "processed 60 senders\n",
      "processed 80 senders\n",
      "processed 100 senders\n",
      "processed 120 senders\n"
     ]
    }
   ],
   "source": [
    "train_info, train_email_ids_per_sender, val_info, val_email_ids_per_sender = scoring.get_train_val(training, training_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constructing dictionnary from dataframe...\n",
      "20000 / 21806\n",
      "0 / 21806\n",
      "40000 / 21806\n",
      "done !\n"
     ]
    }
   ],
   "source": [
    "token_dict = preprocess.body_dict_from_panda(train_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Compute tfidf variables\n",
    "tfidf_model, tfidf_matrix, tfidf_mids = tfidftools.get_tfidf(token_dict, 0.001, 0.10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nb_neighbors_list = [10, 100, 1000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nb_recipients = 10\n",
    "scores = []\n",
    "\n",
    "for nb_neighbors in nb_neighbors_list:\n",
    "    mid_recipient_scores = knntools.compute_similarity_scores(tfidf_model, tfidf_matrix,\n",
    "                                  tfidf_mids, train_info, val_info, nb_similars=nb_neighbors)\n",
    "    knn_predictions = knntools.similar_dic_to_standard(mid_recipient_scores, nb_recipients)\n",
    "    current_score = scoring.compute_prediction_mad(knn_predictions, val_info)\n",
    "    path_to_ranks = 'ranks_val/knn-k-{nb_neighbors}-rec-{nb_recip}'.format(nb_neighbors=nb_neighbors,\n",
    "                                                                     nb_recip=nb_recipients)\n",
    "    with open(path_to_ranks, 'wb') as infile:\n",
    "              pickle.dump(knn_dic, infile)\n",
    "    scores.append(current_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10125087446\n"
     ]
    }
   ],
   "source": [
    "print(current_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  },
  "widgets": {
   "state": {
    "44d0ad9f73de4c8284376f9e0b3ba844": {
     "views": [
      {
       "cell_index": 6
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
