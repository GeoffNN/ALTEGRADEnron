{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "from gensim import corpora, models, similarities\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import operator\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import random\n",
    "import scipy\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "import src.knntools as knntools\n",
    "import src.postprocess as postprocess\n",
    "import src.preprocess as preprocess\n",
    "import src.tfidftools as tfidftools\n",
    "import src.tools as tools\n",
    "import src.recencytools as recency\n",
    "import src.scoring as scoring\n",
    "import src.textembeddingtools as texttools\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_to_data = 'data/'\n",
    "\n",
    "training = pd.read_csv(path_to_data + 'training_set.csv', sep=',', header=0)\n",
    "\n",
    "training_info = pd.read_csv(\n",
    "    path_to_data + 'training_info.csv', sep=',', parse_dates=True, header=0)\n",
    "\n",
    "test = pd.read_csv(path_to_data + 'test_set.csv', sep=',', header=0)\n",
    "\n",
    "test_info = pd.read_csv(path_to_data + 'test_info.csv',\n",
    "                        sep=',', parse_dates=True, header=0)\n",
    "path_to_results = 'results/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing training !\n",
      "\n",
      "Processing val !\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_info, train_email_ids_per_sender, val_info, val_email_ids_per_sender = scoring.get_train_val(training, training_info, train_frac=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constructing dictionnary from dataframe...\n",
      "\n",
      "done !\n"
     ]
    }
   ],
   "source": [
    "body_dict = preprocess.body_dict_from_panda(train_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "token_dict_path = 'variables/token_dict_training'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "token_dict = texttools.get_token_dict(token_dict_path, body_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "rarity_thres = 2\n",
    "email_list = list(token_dict.values())\n",
    "email_list = texttools.remove_rare_words(email_list, threshold_count=rarity_thres)\n",
    "mids = list(token_dict.keys())\n",
    "\n",
    "idx_to_mids = dict(zip(range(len(mids)),mids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Assign unique id to word\n",
    "word_id_dic = corpora.Dictionary(email_list)\n",
    "\n",
    "# Compute email corpush as bow [[(wordid_1_1, count_1_1), ...] ...]\n",
    "email_corpus = [word_id_dic.doc2bow(text) for text in email_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84894\n"
     ]
    }
   ],
   "source": [
    "print(len(word_id_dic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(word_id_dic.token2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "model = models.HdpModel(email_corpus, id2word=word_id_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_vars_path = 'variables/hdp_similarities_{thres_nb}_words_out'.format(thres_nb=rarity_thres)\n",
    "hdp_model, hdp_sims = texttools.compute_hdp_model(email_corpus, word_id_dic,\n",
    "                                                  model_vars_path, overwrite=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "email_body = \"This is an awesomely incredible test for human kind wow wow wow ow \"\n",
    "mids, scores = texttools.get_k_similars(hdp_model,  hdp_sims, word_id_dic, idx_to_mids, email_body, k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  },
  "widgets": {
   "state": {
    "025c31c7c75340129344081fd97cf4e5": {
     "views": [
      {
       "cell_index": 2
      }
     ]
    },
    "45f8e24750df499e9c7b4308cb1542c7": {
     "views": [
      {
       "cell_index": 7
      }
     ]
    },
    "7d1f1cc208104de3a8e3ac987afbba83": {
     "views": [
      {
       "cell_index": 2
      }
     ]
    },
    "8646a7b083ce498a8d8c756f745f9c73": {
     "views": [
      {
       "cell_index": 3
      }
     ]
    },
    "cacc0c8b9d6947208fa436a0cc70de2a": {
     "views": [
      {
       "cell_index": 2
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
